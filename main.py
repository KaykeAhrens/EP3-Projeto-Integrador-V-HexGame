from hexGame import JogoHex
from qlearning_agent import QlearningAgent, comparar_agentes, plotar_metricas
from utils import listar_arquivos_drive, baixar_arquivo_drive
import os
import threading
import time
from colorama import init, Fore, Style
init(autoreset=True)

CAMINHO_MODELOS = "modelos_baixados" # modelos baixados do drive
os.makedirs(CAMINHO_MODELOS, exist_ok=True)

PASTA_DRIVE_ID = "1_PeNiEZy8jhmNWNFVES3bPXU6g8TNzjn"  # ID da pasta do seu Drive

def menu_principal():
    """Menu principal do jogo com op√ß√µes de Q-Learning"""
    print("=" * 50)
    print("üéØ BEM-VINDO AO HEX GAME! üéØ")
    print("=" * 50)
    print("1. üéÆ Jogo Tradicional (Humano vs Humano ou vs Minimax)")
    print("2. üß† Treinar Agente Q-Learning")
    print("3. ü§ñ Jogar contra Agente Q-Learning")
    print("4. ‚öîÔ∏è  Comparar Q-Learning vs Minimax")
    print("5. üìä Visualizar M√©tricas de Treinamento")
    print("6. üíæ Gerenciar Modelos Salvos")
    print("0. üö™ Sair")
    print("=" * 50)

def jogo_tradicional():
    """Executa o jogo tradicional (c√≥digo original)"""
    print("\n=== JOGO HEX TRADICIONAL ===")
    print(f"O jogador {Fore.RED}‚¨¢{Style.RESET_ALL} (X) deve conectar a esquerda √† direita")
    print(f"O jogador {Fore.CYAN}‚¨¢{Style.RESET_ALL} (O) deve conectar o topo √† base")
    
    tamanho = 11
    try:
        tamanho_input = int(input("Digite o tamanho do tabuleiro (3-11, padr√£o: 11): "))
        if 3 <= tamanho_input <= 11:
            tamanho = tamanho_input
        else:
            print("Tamanho inv√°lido! Usando o tamanho padr√£o de 11x11.")
    except ValueError:
        print("Entrada inv√°lida! Usando o tamanho padr√£o de 11x11.")
    
    jogo = JogoHex(tamanho)
    jogo.jogar()

def treinar_agente():
    """Interface para treinar um novo agente Q-Learning"""
    print("\n=== TREINAMENTO DO AGENTE Q-LEARNING ===")
    
    # Configura√ß√µes do tabuleiro
    try:
        tamanho = int(input("Tamanho do tabuleiro (3-11, padr√£o 7): ") or "7")
        if not (3 <= tamanho <= 11):
            tamanho = 7
    except ValueError:
        tamanho = 7
    
    # Configura√ß√µes de treinamento
    try:
        num_episodios = int(input("N√∫mero de epis√≥dios (padr√£o 5000): ") or "5000")
    except ValueError:
        num_episodios = 5000
    
    # Tipo de oponente
    print("\nTipos de oponente dispon√≠veis:")
    print("1. aleatorio - Jogadas aleat√≥rias (mais r√°pido)")
    print("2. minimax - Algoritmo Minimax (mais lento, melhor qualidade)")
    
    tipo_oponente = input("Escolha o tipo de oponente (1 ou 2, padr√£o 1): ")
    if tipo_oponente == "2":
        oponente = "minimax"
    else:
        oponente = "aleatorio"
    
    # Par√¢metros do Q-Learning
    print("\n=== PAR√ÇMETROS DO Q-LEARNING ===")
    try:
        alpha = float(input("Taxa de aprendizado Œ± (0.0-1.0, padr√£o 0.1): ") or "0.1")
        gamma = float(input("Fator de desconto Œ≥ (0.0-1.0, padr√£o 0.9): ") or "0.9")
        epsilon = float(input("Taxa de explora√ß√£o inicial Œµ (0.0-1.0, padr√£o 1.0): ") or "1.0")
    except ValueError:
        alpha, gamma, epsilon = 0.1, 0.9, 1.0
        print("Usando par√¢metros padr√£o: Œ±=0.1, Œ≥=0.9, Œµ=1.0")
    
    # Cria e treina o agente
    agente = QlearningAgent(
        tamanho_tabuleiro=tamanho,
        alpha=alpha,
        gamma=gamma,
        epsilon=epsilon
    )
    
    # Nome do arquivo
    nome_arquivo = input(f"Nome do arquivo para salvar (padr√£o qlearning_{tamanho}x{tamanho}_{num_episodios}ep.pkl): ") or f"qlearning_{tamanho}x{tamanho}_{num_episodios}ep.pkl"
    
    print(f"\nüöÄ Iniciando treinamento...")
    print(f"üìã Configura√ß√µes:")
    print(f"   - Tabuleiro: {tamanho}x{tamanho}")
    print(f"   - Epis√≥dios: {num_episodios}")
    print(f"   - Oponente: {oponente}")
    print(f"   - Par√¢metros: Œ±={alpha}, Œ≥={gamma}, Œµ={epsilon}")
    print(f"   - Arquivo: {nome_arquivo}")
    
    # Confirma antes de iniciar
    continuar = input("\nDeseja continuar com o treinamento? (s/n): ").lower()
    if continuar != 's':
        print("Treinamento cancelado.")
        return
    
    # Executa o treinamento
    agente.treinar(
        num_episodios=num_episodios,
        oponente=oponente,
        salvar_a_cada=max(100, num_episodios//10),
        nome_arquivo=nome_arquivo
    )
    
    print("\n‚úÖ Treinamento conclu√≠do!")
    
    # Op√ß√µes p√≥s-treinamento
    print("\n=== OP√á√ïES P√ìS-TREINAMENTO ===")
    print("1. üìä Visualizar m√©tricas")
    print("2. üéÆ Jogar contra o agente")
    print("3. ‚öîÔ∏è Comparar com Minimax")
    print("4. üîô Voltar ao menu principal")
    
    opcao = input("Escolha uma op√ß√£o: ")
    
    if opcao == "1":
        plotar_metricas(agente)
    elif opcao == "2":
        agente.jogar_contra_humano()
    elif opcao == "3":
        num_jogos = int(input("N√∫mero de jogos para compara√ß√£o (padr√£o 50): ") or "50")
        comparar_agentes(agente, num_jogos, tamanho)
    
def jogar_contra_qlearning():
    """Interface para jogar contra um agente Q-Learning treinado - Tabuleiro 7x7"""
    print("\n=== JOGAR CONTRA AGENTE Q-LEARNING (7x7) ===")
    
    # Modelos locais
    print("üìÅ Buscando modelos locais...")
    modelos_locais = []
    if os.path.exists(CAMINHO_MODELOS):
        modelos_locais = [
            {"name": f, "origem": "local"}
            for f in os.listdir(CAMINHO_MODELOS) if f.endswith(".pkl")
        ]

    # Modelos do Drive
    print("üåê Buscando modelos no Google Drive...")
    try:
        arquivos_drive = listar_arquivos_drive(PASTA_DRIVE_ID)
        modelos_drive = [
            {"name": f["name"], "id": f["id"], "origem": "drive"}
            for f in arquivos_drive
            if f["name"].endswith(".pkl")
        ]
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao listar modelos do Drive: {e}")
        modelos_drive = []

    modelos_disponiveis = modelos_locais + modelos_drive
    
    if not modelos_disponiveis:
        print("‚ùå Nenhum modelo dispon√≠vel!")
        print("üí° Sugest√£o: Treine um agente primeiro usando a op√ß√£o 2 do menu principal.")
        return
    
    print("\nModelos dispon√≠veis:")
    for i, modelo in enumerate(modelos_disponiveis, 1):
        origem = "Drive" if modelo["origem"] == "drive" else "Local"
        print(f"{i}. {modelo['name']} [{origem}]")
    
    try:
        escolha = int(input("Escolha um modelo (n√∫mero): ")) - 1
        if 0 <= escolha < len(modelos_disponiveis):
            modelo_escolhido = modelos_disponiveis[escolha]
        else:
            print("‚ùå Escolha inv√°lida!")
            return
    except ValueError:
        print("‚ùå Entrada inv√°lida! Por favor, digite apenas o n√∫mero.")
        return
    
    # Carrega o agente
    try:
        agente = QlearningAgent()
        if modelo_escolhido["origem"] == "drive":
            caminho_local = baixar_arquivo_drive(modelo_escolhido["id"], modelo_escolhido["name"])
        else:
            caminho_local = os.path.join(CAMINHO_MODELOS, modelo_escolhido["name"])
        
        agente.carregar_modelo(caminho_local)
        
        # FOR√áA O TABULEIRO A SER 7x7 INDEPENDENTE DO MODELO
        agente.tamanho_tabuleiro = 7
        
        print(f"\n‚úÖ Modelo carregado: {modelo_escolhido['name']}")
        print(f"üéØ Tabuleiro configurado para: 7x7")
        print(f"üìä Estat√≠sticas do modelo:")
        total_jogos = agente.vitorias + agente.derrotas
        if total_jogos > 0:
            print(f"   - Vit√≥rias: {agente.vitorias} ({agente.vitorias/total_jogos*100:.1f}%)")
            print(f"   - Derrotas: {agente.derrotas} ({agente.derrotas/total_jogos*100:.1f}%)")
            print(f"   - Tamanho da Q-table: {len(agente.q_table)} entradas")
        
        # Inicia o jogo
        agente.jogar_contra_humano()
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar modelo: {e}")

def comparar_agentes_interface():
    """Interface para comparar Q-Learning vs Minimax"""
    print("\n=== COMPARA√á√ÉO Q-LEARNING VS MINIMAX ===")
    
    # Modelos locais
    print("üìÅ Buscando modelos locais...")
    modelos_locais = []
    if os.path.exists(CAMINHO_MODELOS):
        modelos_locais = [
            {"name": f, "origem": "local"}
            for f in os.listdir(CAMINHO_MODELOS) if f.endswith(".pkl")
        ]

    # Modelos do Drive
    print("üåê Buscando modelos no Google Drive...")
    try:
        arquivos_drive = listar_arquivos_drive(PASTA_DRIVE_ID)
        modelos_drive = [
            {"name": f["name"], "id": f["id"], "origem": "drive"}
            for f in arquivos_drive
            if f["name"].endswith(".pkl")
        ]
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao listar modelos do Drive: {e}")
        modelos_drive = []

    modelos_disponiveis = modelos_locais + modelos_drive
    
    if not modelos_disponiveis:
        print("‚ùå Nenhum modelo dispon√≠vel!")
        return
    
    print("\nModelos dispon√≠veis:")
    for i, modelo in enumerate(modelos_disponiveis, 1):
        origem = "Drive" if modelo["origem"] == "drive" else "Local"
        print(f"{i}. {modelo['name']} [{origem}]")
    
    try:
        escolha = int(input("Escolha um modelo (n√∫mero): ")) - 1
        if 0 <= escolha < len(modelos_disponiveis):
            modelo_escolhido = modelos_disponiveis[escolha]
        else:
            print("‚ùå Escolha inv√°lida!")
            return
    except ValueError:
            print("‚ö†Ô∏è Entrada inv√°lida! Por favor, digite apenas o n√∫mero da lista.")
            return
    
    try:
        num_jogos = int(input("N√∫mero de jogos para compara√ß√£o (padr√£o 100): ") or "100")
    except ValueError:
        num_jogos = 100
    
    # Carrega o agente e executa a compara√ß√£o
    try:
        agente = QlearningAgent()
        if modelo_escolhido["origem"] == "drive":
            caminho_local = baixar_arquivo_drive(modelo_escolhido["id"], modelo_escolhido["name"])
        else:
            caminho_local = os.path.join(CAMINHO_MODELOS, modelo_escolhido["name"])
        agente.carregar_modelo(caminho_local)
        
        print(f"\nüîÑ Iniciando compara√ß√£o com {num_jogos} jogos...")
        print("‚è±Ô∏è Isso pode demorar alguns minutos...")
        
        vitorias_q, vitorias_minimax, empates = comparar_agentes(
            agente, 
            num_jogos=num_jogos, 
            tamanho_tabuleiro=agente.tamanho_tabuleiro
        )
        
        # An√°lise detalhada dos resultados
        print(f"\nüìä AN√ÅLISE DETALHADA:")
        print(f"üéØ Performance do Q-Learning: {vitorias_q/num_jogos*100:.1f}%")
        print(f"ü§ñ Performance do Minimax: {vitorias_minimax/num_jogos*100:.1f}%")
        print(f"ü§ù Empates: {empates} ({empates/num_jogos*100:.1f}%)")
        
        if vitorias_q > vitorias_minimax:
            print("üèÜ Q-Learning se saiu melhor!")
        elif vitorias_minimax > vitorias_q:
            print("üèÜ Minimax se saiu melhor!")
        else:
            print("ü§ù Empate t√©cnico!")
            
    except Exception as e:
        print(f"‚ùå Erro durante a compara√ß√£o: {e}")

def visualizar_metricas():
    """Interface para visualizar m√©tricas de treinamento"""
    print("\n=== VISUALIZA√á√ÉO DE M√âTRICAS ===")
    
    # Modelos locais
    print("üìÅ Buscando modelos locais...")
    modelos_locais = []
    if os.path.exists(CAMINHO_MODELOS):
        modelos_locais = [
            {"name": f, "origem": "local"}
            for f in os.listdir(CAMINHO_MODELOS) if f.endswith(".pkl")
        ]

    # Modelos do Drive
    print("üåê Buscando modelos no Google Drive...")
    try:
        arquivos_drive = listar_arquivos_drive(PASTA_DRIVE_ID)
        modelos_drive = [
            {"name": f["name"], "id": f["id"], "origem": "drive"}
            for f in arquivos_drive
            if f["name"].endswith(".pkl")
        ]
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao listar modelos do Drive: {e}")
        modelos_drive = []

    modelos_disponiveis = modelos_locais + modelos_drive

    if not modelos_disponiveis:
        print("‚ùå Nenhum modelo Q-Learning encontrado!")
        return

    # Lista todos os modelos
    print("\nModelos dispon√≠veis:")
    for i, modelo in enumerate(modelos_disponiveis, 1):
        origem = "Drive" if modelo["origem"] == "drive" else "Local"
        print(f"{i}. {modelo['name']} [{origem}]")

    try:
        escolha = int(input("Escolha um modelo (n√∫mero): ")) - 1
        if 0 <= escolha < len(modelos_disponiveis):
            modelo = modelos_disponiveis[escolha]
            if modelo["origem"] == "drive":
                caminho_local = baixar_arquivo_drive(modelo["id"], modelo["name"])
            else:
                caminho_local = os.path.join(CAMINHO_MODELOS, modelo["name"])
        else:
            print("‚ùå Escolha inv√°lida!")
            return
    except ValueError:
        print("‚ùå Entrada inv√°lida.")
        return

    try:
        agente = QlearningAgent()
        agente.carregar_modelo(caminho_local)
        plotar_metricas(agente)
    except Exception as e:
        print(f"‚ùå Erro ao carregar modelo: {e}")


def gerenciar_modelos():
    """Interface para gerenciar modelos salvos locais e do Google Drive"""
    print("\n=== GERENCIAMENTO DE MODELOS ===")

    # Modelos locais
    modelos_locais = []
    if os.path.exists(CAMINHO_MODELOS):
        modelos_locais = [
            {"name": f, "origem": "local"}
            for f in os.listdir(CAMINHO_MODELOS) if f.endswith(".pkl")
        ]

    # Modelos no Google Drive
    try:
        arquivos_drive = listar_arquivos_drive(PASTA_DRIVE_ID)
        modelos_drive = [
            {"name": f["name"], "id": f["id"], "origem": "drive"}
            for f in arquivos_drive if f["name"].endswith(".pkl")
        ]
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao listar modelos do Drive: {e}")
        modelos_drive = []

    modelos_disponiveis = modelos_locais + modelos_drive

    if not modelos_disponiveis:
        print("‚ùå Nenhum modelo encontrado!")
        return

    print("üìÅ Modelos dispon√≠veis:")
    for i, modelo in enumerate(modelos_disponiveis, 1):
        origem = "Drive" if modelo["origem"] == "drive" else "Local"
        print(f"{i}. {modelo['name']} [{origem}]")

    print("\n=== OP√á√ïES ===")
    print("1. üìä Ver detalhes de um modelo")
    print("2. üóëÔ∏è  Deletar um modelo (apenas local)")
    print("3. üìÑ Renomear um modelo (apenas local)")
    print("4. üîô Voltar ao menu principal")

    opcao = input("Escolha uma op√ß√£o: ")

    if opcao == "1":
        try:
            escolha = int(input("Escolha um modelo para ver detalhes (n√∫mero): ")) - 1
            if 0 <= escolha < len(modelos_disponiveis):
                modelo = modelos_disponiveis[escolha]

                if modelo["origem"] == "drive":
                    caminho_local = baixar_arquivo_drive(modelo["id"], modelo["name"])
                else:
                    caminho_local = os.path.join(CAMINHO_MODELOS, modelo["name"])

                agente = QlearningAgent()
                agente.carregar_modelo(caminho_local)

                print(f"\nüìä DETALHES DO MODELO: {modelo['name']}")
                print(f"üéØ Tamanho do tabuleiro: {agente.tamanho_tabuleiro}x{agente.tamanho_tabuleiro}")
                print(f"üß† Tamanho da Q-table: {len(agente.q_table)} entradas")
                print(f"üìà Par√¢metros: Œ±={agente.alpha}, Œ≥={agente.gamma}")

                total_jogos = agente.vitorias + agente.derrotas
                if total_jogos > 0:
                    print(f"üèÜ Vit√≥rias: {agente.vitorias} ({agente.vitorias/total_jogos*100:.1f}%)")
                    print(f"üíî Derrotas: {agente.derrotas} ({agente.derrotas/total_jogos*100:.1f}%)")
                    print(f"üéÆ Total de epis√≥dios: {total_jogos}")
        except Exception as e:
            print(f"‚ùå Erro: {e}")

    elif opcao == "2":
        try:
            escolha = int(input("Escolha um modelo local para deletar (n√∫mero): ")) - 1
            if 0 <= escolha < len(modelos_disponiveis):
                modelo = modelos_disponiveis[escolha]
                if modelo["origem"] == "local":
                    confirmar = input(f"‚ùó Tem certeza que deseja deletar '{modelo['name']}'? (s/n): ").lower()
                    if confirmar == 's':
                        os.remove(os.path.join(CAMINHO_MODELOS, modelo["name"]))
                        print(f"‚úÖ Modelo '{modelo['name']}' deletado com sucesso!")
                    else:
                        print("‚ùå Opera√ß√£o cancelada.")
                else:
                    print("‚ùå N√£o √© poss√≠vel deletar arquivos do Drive.")
        except Exception as e:
            print(f"‚ùå Erro ao deletar: {e}")

    elif opcao == "3":
        try:
            escolha = int(input("Escolha um modelo local para renomear (n√∫mero): ")) - 1
            if 0 <= escolha < len(modelos_disponiveis):
                modelo = modelos_disponiveis[escolha]
                if modelo["origem"] == "local":
                    nome_antigo = modelo["name"]
                    nome_novo = input("Digite o novo nome (sem extens√£o): ")
                    if not nome_novo.endswith('.pkl'):
                        nome_novo += '.pkl'

                    os.rename(
                        os.path.join(CAMINHO_MODELOS, nome_antigo),
                        os.path.join(CAMINHO_MODELOS, nome_novo)
                    )
                    print(f"‚úÖ Modelo renomeado de '{nome_antigo}' para '{nome_novo}'!")
                else:
                    print("‚ùå N√£o √© poss√≠vel renomear arquivos do Drive.")
        except Exception as e:
            print(f"‚ùå Erro ao renomear: {e}")

    elif opcao == "4":
        return

    else:
        print("‚ùå Op√ß√£o inv√°lida.")

def main():
    """Fun√ß√£o principal com loop do menu"""
    while True:
        try:
            menu_principal()
            opcao = input("Escolha uma op√ß√£o (0-6): ").strip()
            
            if opcao == "0":
                print("\nüëã Obrigado por jogar! At√© logo!")
                break
            elif opcao == "1":
                jogo_tradicional()
            elif opcao == "2":
                treinar_agente()
            elif opcao == "3":
                jogar_contra_qlearning()
            elif opcao == "4":
                comparar_agentes_interface()
            elif opcao == "5":
                visualizar_metricas()
            elif opcao == "6":
                gerenciar_modelos()
            else:
                print("‚ùå Op√ß√£o inv√°lida! Escolha um n√∫mero de 0 a 6.")
            
            # Pausa antes de voltar ao menu
            if opcao != "0":
                input("\nüìÑ Pressione Enter para voltar ao menu principal...")
                print("\n" + "="*50)
        
        except KeyboardInterrupt:
            print("\n\nüëã Programa interrompido pelo usu√°rio. At√© logo!")
            break
        except Exception as e:
            print(f"\n‚ùå Erro inesperado: {e}")
            print("üîÑ Voltando ao menu principal...")

if __name__ == "__main__":
    print("üéØ Inicializando Hex Game...")
    main()